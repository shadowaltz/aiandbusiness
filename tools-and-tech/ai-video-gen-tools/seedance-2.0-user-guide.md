# Seedance 2.0:  User Guide

{% embed url="https://seed.bytedance.com/en/seedance2_0" %}

## Seedance 2.0: Comprehensive English User Guide

### 1. Introduction to Seedance 2.0

Seedance 2.0 represents a breakthrough in generative AI, utilizing a unified multimodal audio-video joint generation architecture. Unlike traditional models that rely solely on text-to-video diffusion, Seedance 2.0 integrates text, image, audio, and video inputs into a single framework. This architecture provides the industryâ€™s most comprehensive suite of multimodal content reference and editing capabilities, allowing for unprecedented creative precision.

#### Key Value Propositions

* **Immersive Audio-visual Experience:** Achieve ultra-realistic results through exceptional motion stability and native audio-video synchronization.
* **Director-level Control:** Move beyond "prompting" to "directing" by exerting granular control over performance, lighting, and cinematography through multimodal references.
* **Cinematic Output:** Generate high-fidelity assets aligned with professional industry standards, significantly reducing production cycles for professional creators.

\--------------------------------------------------------------------------------

### 2. Platform Access and Getting Started

Seedance 2.0 is officially hosted on the Jimeng platform (also known as "Jimeng" in Chinese contexts). To ensure optimal performance and access to the latest feature set, follow these steps:

* Official URL:&#x20;
* Model Selection: Locate the model selection toggle within the generation settings panel. Select your desired engine based on current requirements:
  * Seedance 2.0: The flagship full-power model, optimized for maximum quality and high-fidelity reference adherence.
  * Seedance 2.0 Fast: A high-efficiency alternative optimized for lower latency.
  * Pro-Tip: During peak traffic hours when server pressure is high, switch to Seedance 2.0 Fast to maintain a smooth creative workflow. This model remains an underutilized resource for power users looking to bypass wait times.

\--------------------------------------------------------------------------------

### 3. Unified Multimodal Architecture

Seedance 2.0 supports four distinct input modalities. While each serves a specific functional role, the Text modality acts as the "connective tissue," resolving ambiguities and bridging the gap between visual references and auditory atmospheres.

#### Supported Input Modalities

| Modality | Technical Input Type            | Functional Role in Generation                                    |
| -------- | ------------------------------- | ---------------------------------------------------------------- |
| Text     | Natural language prompts        | Resolves semantic conflict and bridges other reference inputs.   |
| Image    | Static visual uploads (JPG/PNG) | Defines visual style, character traits, and initial composition. |
| Audio    | Sound clips or temporal guides  | Establishes the rhythmic pacing and emotional atmosphere.        |
| Video    | Short reference clips (MP4/MOV) | Dictates character kinetics and complex camera trajectories.     |

\--------------------------------------------------------------------------------

### 4. Advanced Reference-Based Creation

The "Reference Ability" of Seedance 2.0 is the platform's primary differentiator. To maximize the accuracy of your output, utilize references according to the following instructional guidelines:

* Prioritize Image References for Consistency: To maintain character features and precise screen composition across multiple generations, upload a high-resolution base image.
* Define Kinetics through Video References: Use video clips to specify complex character choreography or specific camera movement changes that are difficult to articulate through text alone.
* Synchronize Atmosphere with Audio: Incorporate audio files to set the tempo of the visual generation. Seedance 2.0 will align the motion within the video to the rhythm and mood of the soundscape.
* Refine Narratives with Prompts: Use text to direct the overall narrative flow. When using multiple references (e.g., an image and an audio clip), the text prompt should be used to describe the action that links the two.

\--------------------------------------------------------------------------------

### 5. Director-Level Creative Controls

The Seedance 2.0 interface allows creators to configure specific technical parameters through multimodal references. When setting up your creative environment, ensure the following parameters are addressed to achieve cinematic-grade efficiency:

#### Creative Parameter Checklist

* Character Choreography and Behavioral Consistency: Control the kinetics and physical performance of subjects via video references.
* Lighting Schematics: Define the source, intensity, and temperature of light within the scene to match professional lighting setups.
* Spatial Depth and Occlusion: Manage the relationship between foreground and background elements for realistic spatial depth.
* Cinematographic Trajectory: Manage pans, tilts, zooms, and complex tracking shots by utilizing motion guides.

\--------------------------------------------------------------------------------

### 6. Model Performance and Benchmarks

The Seedance 2.0 architecture has been rigorously validated against SeedVideoBench-2.0, an industry-leading internal evaluation framework.

#### Multi-Dimensional Evaluation

Internal benchmarks, visualized through comprehensive Radar Charts, indicate that Seedance 2.0 maintains a leading position across three primary categories:

1. Text-to-Video: High semantic alignment and prompt adherence.
2. Image-to-Video: Superior temporal stability and preservation of image fidelity.
3. Multimodal Integration: The industry's best performance in simultaneous multi-source synthesis.

The model consistently demonstrates a "balanced pentagon" of performance on evaluation charts, particularly excelling in motion stability and semantic alignment compared to its predecessors.





